{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MunWbHBXlSpi",
        "duuukZlB7kEM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eXNcXZXPkSfV"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"The cat drinks the milk\",\n",
        "    \"The cow eats in the park\",\n",
        "    \"The fish swims in the lake\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the corpus (split sentences into words)\n",
        "tokens = [sentence.lower().split() for sentence in corpus]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "latPZo3xllf6",
        "outputId": "8d8d6044-be3f-4652-da5e-af875ad5d1df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'cat', 'drinks', 'the', 'milk'],\n",
              " ['the', 'cow', 'eats', 'in', 'the', 'park'],\n",
              " ['the', 'fish', 'swims', 'in', 'the', 'lake']]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding\n",
        "\n",
        "One-Hot Encoding represents each word as a unique binary vector, where only one element is 1, and all others are 0.\n",
        "\n",
        "‚öôÔ∏è What it does?\n",
        "*   Identify unique words in the corpus.\n",
        "*   Assign a unique index to each word.\n",
        "*   Convert words into binary vectors, where each vector has a 1 in the corresponding index."
      ],
      "metadata": {
        "id": "MunWbHBXlSpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nUNIWtyWmUpw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique words from the corpus\n",
        "unique_words = sorted(set(word for sentence in tokens for word in sentence))"
      ],
      "metadata": {
        "id": "9Dvdc3KGlXfa"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding using sklearn\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "one_hot_vectors = encoder.fit_transform(np.array(unique_words).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "yA4UQadFmKI3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OneHotEncoder(sparse=False): sparse=False ensures the output is a dense NumPy array instead of a sparse matrix.\n",
        "\n",
        "fit_transform(): Learns unique word indices and encodes them into one-hot vectors."
      ],
      "metadata": {
        "id": "sLP1nJmH9_Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the one-hot encoded vectors\n",
        "print(\"\\nOne-Hot Encoding:\")\n",
        "for word, vector in zip(unique_words, one_hot_vectors):\n",
        "    print(f\"{word}: {vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bilk7rbW-Fh4",
        "outputId": "4791f70a-be78-4a92-99f1-de8ed02fbe90"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "One-Hot Encoding:\n",
            "cat: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "cow: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "drinks: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "eats: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "fish: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "in: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "lake: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "milk: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "park: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "swims: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "the: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag Of Words (BOW)\n",
        "The Bag of Words (BoW) model represents text as a word frequency matrix, ignoring word order but counting occurrences.\n",
        "\n",
        "‚öôÔ∏è Mechanism\n",
        "*   Tokenize sentences into words.\n",
        "*   Create a vocabulary of unique words.\n",
        "*   Count occurrences of each word in each document.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "duuukZlB7kEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "1N9pDj-87o0R"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize BoW vectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Extract feature names (words)\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "ZlLNuaxv7p4P"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer():Converts text into a word frequency matrix.\n",
        "\n",
        "fit_transform(corpus): Learns vocabulary and creates the document-term matrix.\n",
        "\n",
        "get_feature_names_out(): Retrieves feature names (words in the vocabulary)."
      ],
      "metadata": {
        "id": "BK11XqSN-tUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display BoW representation\n",
        "print(\"\\nBag of Words Representation:\")\n",
        "for doc_id, vector in enumerate(bow_matrix.toarray()):\n",
        "    print(f\"\\nDocument {doc_id+1}:\")\n",
        "    for word, count in zip(feature_names, vector):\n",
        "        print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGJNrl8U7u6M",
        "outputId": "49f0a368-bf7b-4820-9dd3-858cfe932f4f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words Representation:\n",
            "\n",
            "Document 1:\n",
            "cat: 1\n",
            "cow: 0\n",
            "drinks: 1\n",
            "eats: 0\n",
            "fish: 0\n",
            "in: 0\n",
            "lake: 0\n",
            "milk: 1\n",
            "park: 0\n",
            "swims: 0\n",
            "the: 2\n",
            "\n",
            "Document 2:\n",
            "cat: 0\n",
            "cow: 1\n",
            "drinks: 0\n",
            "eats: 1\n",
            "fish: 0\n",
            "in: 1\n",
            "lake: 0\n",
            "milk: 0\n",
            "park: 1\n",
            "swims: 0\n",
            "the: 2\n",
            "\n",
            "Document 3:\n",
            "cat: 0\n",
            "cow: 0\n",
            "drinks: 0\n",
            "eats: 0\n",
            "fish: 1\n",
            "in: 1\n",
            "lake: 1\n",
            "milk: 0\n",
            "park: 0\n",
            "swims: 1\n",
            "the: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N-Gram Model\n",
        "\n",
        "An N-Gram Model captures word sequences (e.g., bigrams, trigrams) instead of individual words, preserving some context.\n",
        "\n",
        "‚öôÔ∏è Mechanism\n",
        "*   Tokenize text into n-word sequences.\n",
        "*   Count occurrences of n-grams in documents.\n",
        "*   Represent text as a frequency matrix.\n"
      ],
      "metadata": {
        "id": "UySUiAxK73ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize N-Gram Vectorizer (bigrams)\n",
        "vectorizer_ngram = CountVectorizer(ngram_range=(2, 2))\n",
        "ngram_matrix = vectorizer_ngram.fit_transform(corpus)\n",
        "\n",
        "# Extract feature names (bigrams)\n",
        "feature_names_ngram = vectorizer_ngram.get_feature_names_out()"
      ],
      "metadata": {
        "id": "65IjVbXn79B6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ngram_range=(2,2): Extracts bigrams instead of single words.\n",
        "\n",
        "fit_transform(): Converts text into an n-gram frequency matrix."
      ],
      "metadata": {
        "id": "ap-Dea6o-5F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display N-Gram representation\n",
        "print(\"\\nN-Gram Representation (Bigrams):\")\n",
        "for doc_id, vector in enumerate(ngram_matrix.toarray()):\n",
        "    print(f\"\\nDocument {doc_id+1}:\")\n",
        "    for word, count in zip(feature_names_ngram, vector):\n",
        "        print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuSAVWMo7-AS",
        "outputId": "49fb61fc-2f85-4046-cc2c-d2a7b0854ab5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "N-Gram Representation (Bigrams):\n",
            "\n",
            "Document 1:\n",
            "cat drinks: 1\n",
            "cow eats: 0\n",
            "drinks the: 1\n",
            "eats in: 0\n",
            "fish swims: 0\n",
            "in the: 0\n",
            "swims in: 0\n",
            "the cat: 1\n",
            "the cow: 0\n",
            "the fish: 0\n",
            "the lake: 0\n",
            "the milk: 1\n",
            "the park: 0\n",
            "\n",
            "Document 2:\n",
            "cat drinks: 0\n",
            "cow eats: 1\n",
            "drinks the: 0\n",
            "eats in: 1\n",
            "fish swims: 0\n",
            "in the: 1\n",
            "swims in: 0\n",
            "the cat: 0\n",
            "the cow: 1\n",
            "the fish: 0\n",
            "the lake: 0\n",
            "the milk: 0\n",
            "the park: 1\n",
            "\n",
            "Document 3:\n",
            "cat drinks: 0\n",
            "cow eats: 0\n",
            "drinks the: 0\n",
            "eats in: 0\n",
            "fish swims: 1\n",
            "in the: 1\n",
            "swims in: 1\n",
            "the cat: 0\n",
            "the cow: 0\n",
            "the fish: 1\n",
            "the lake: 1\n",
            "the milk: 0\n",
            "the park: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF\n",
        "TF-IDF measures word importance based on how frequently a word appears in a document and how rare it is across the corpus.\n",
        "\n",
        "‚öôÔ∏è Mechanism\n",
        "\n",
        "Compute TF (Term Frequency):\n",
        "*  ùëáùêπ(ùë§)= Number of times word appears in a document / Total words in the document\n",
        "\n",
        "Compute IDF (Inverse Document Frequency):\n",
        "*   ùêºùê∑ùêπ(ùë§)= log (Total number of documents / Number of documents containing word w)\n",
        "\n",
        "Multiply TF and IDF to get TF-IDF score."
      ],
      "metadata": {
        "id": "pe7iAZlb5GGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "y9H8BOmPmXqD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Extract feature names (words)\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "0W1mFtle5PrW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TfidfVectorizer():Converts text into a weighted word frequency matrix.\n",
        "\n",
        "fit_transform(corpus): Computes TF-IDF scores for each word.\n"
      ],
      "metadata": {
        "id": "ma2CrkQ__GFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the TF-IDF vectors for each document\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "for doc_id, vector in enumerate(tfidf_matrix.toarray()):\n",
        "    print(f\"\\nDocument {doc_id+1}:\")\n",
        "    for word, score in zip(feature_names, vector):\n",
        "        print(f\"{word}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5pTCytq_CpH",
        "outputId": "68ad5f16-e575-459a-acca-962615ab9f54"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Representation:\n",
            "\n",
            "Document 1:\n",
            "cat: 0.4770\n",
            "cow: 0.0000\n",
            "drinks: 0.4770\n",
            "eats: 0.0000\n",
            "fish: 0.0000\n",
            "in: 0.0000\n",
            "lake: 0.0000\n",
            "milk: 0.4770\n",
            "park: 0.0000\n",
            "swims: 0.0000\n",
            "the: 0.5634\n",
            "\n",
            "Document 2:\n",
            "cat: 0.0000\n",
            "cow: 0.4484\n",
            "drinks: 0.0000\n",
            "eats: 0.4484\n",
            "fish: 0.0000\n",
            "in: 0.3410\n",
            "lake: 0.0000\n",
            "milk: 0.0000\n",
            "park: 0.4484\n",
            "swims: 0.0000\n",
            "the: 0.5297\n",
            "\n",
            "Document 3:\n",
            "cat: 0.0000\n",
            "cow: 0.0000\n",
            "drinks: 0.0000\n",
            "eats: 0.0000\n",
            "fish: 0.4484\n",
            "in: 0.3410\n",
            "lake: 0.4484\n",
            "milk: 0.0000\n",
            "park: 0.0000\n",
            "swims: 0.4484\n",
            "the: 0.5297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2Vec (CBOW & Skip-Gram)\n",
        "\n",
        "Word2Vec is a neural network model that generates dense word embeddings based on context.\n",
        "\n",
        "‚öôÔ∏è Mechanism\n",
        "\n",
        "CBOW (Continuous Bag of Words): Predicts a word given its surrounding context.\n",
        "\n",
        "Skip-Gram: Predicts surrounding words given a word."
      ],
      "metadata": {
        "id": "wpw9o2Xj6FcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "W7YD-IQZ6JqD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW"
      ],
      "metadata": {
        "id": "JrFNfdZm6ccR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model (CBOW)\n",
        "w2v_model_cbow = Word2Vec(sentences=tokens, vector_size=5, window=2, min_count=1, sg=0)"
      ],
      "metadata": {
        "id": "N-JtMtWI6OQj"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vector_size=5:Word vectors have 5 dimensions.\n",
        "\n",
        "window=2:Considers 2 words on either side as context.\n",
        "\n",
        "sg=0:Uses CBOW (if sg=1, uses Skip-Gram)"
      ],
      "metadata": {
        "id": "KRMbEH0n_Ttn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display word vectors for CBOW\n",
        "print(\"\\nWord2Vec CBOW Representation:\")\n",
        "for word in unique_words:\n",
        "    print(f\"{word}: {w2v_model_cbow.wv[word]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn1u6Wp8_bWh",
        "outputId": "300a4da8-3745-437f-a38f-1dc78ec35099"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word2Vec CBOW Representation:\n",
            "cat: [-0.16315834  0.08991597 -0.08274152  0.01649072  0.16997239]\n",
            "cow: [-0.03875482  0.16154873 -0.11861791  0.00090325 -0.09507468]\n",
            "drinks: [-0.00592363 -0.1532248   0.19229487  0.09964116  0.18466286]\n",
            "eats: [-0.15023164 -0.01860085  0.19076237 -0.14638333 -0.04667537]\n",
            "fish: [0.14623532 0.10140524 0.13515386 0.01525731 0.12701781]\n",
            "in: [-0.14233617  0.12917745  0.17945977 -0.10030856 -0.07526743]\n",
            "lake: [ 0.1476101  -0.03066943 -0.09073226  0.13108103 -0.09720321]\n",
            "milk: [-0.192071    0.10014586 -0.17519172 -0.0878365  -0.000702  ]\n",
            "park: [-0.06810732 -0.01892803  0.11537147 -0.15043275 -0.07872207]\n",
            "swims: [-0.03632035  0.0575316   0.01983747 -0.1657043  -0.18897636]\n",
            "the: [-0.01072454  0.00472863  0.10206699  0.18018547 -0.186059  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skip-Gram"
      ],
      "metadata": {
        "id": "i8YEr4506fr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model (Skip-Gram)\n",
        "w2v_model_skipgram = Word2Vec(sentences=tokens, vector_size=5, window=2, min_count=1, sg=1)\n",
        "\n",
        "# Display word vectors for Skip-Gram\n",
        "print(\"\\nWord2Vec Skip-Gram Representation:\")\n",
        "for word in unique_words:\n",
        "    print(f\"{word}: {w2v_model_skipgram.wv[word]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XvuXFUL6Ull",
        "outputId": "fca49dcc-5f58-4c1a-b73f-24aceb84d1c1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word2Vec Skip-Gram Representation:\n",
            "cat: [-0.16315834  0.08991597 -0.08274152  0.01649072  0.16997239]\n",
            "cow: [-0.03875482  0.16154873 -0.11861791  0.00090325 -0.09507468]\n",
            "drinks: [-0.00592363 -0.1532248   0.19229487  0.09964116  0.18466286]\n",
            "eats: [-0.15023164 -0.01860085  0.19076237 -0.14638333 -0.04667537]\n",
            "fish: [0.14623532 0.10140524 0.13515386 0.01525731 0.12701781]\n",
            "in: [-0.14233617  0.12917745  0.17945977 -0.10030856 -0.07526743]\n",
            "lake: [ 0.1476101  -0.03066943 -0.09073226  0.13108103 -0.09720321]\n",
            "milk: [-0.192071    0.10014586 -0.17519172 -0.0878365  -0.000702  ]\n",
            "park: [-0.06810732 -0.01892803  0.11537147 -0.15043275 -0.07872207]\n",
            "swims: [-0.03632035  0.0575316   0.01983747 -0.1657043  -0.18897636]\n",
            "the: [-0.01072454  0.00472863  0.10206699  0.18018547 -0.186059  ]\n"
          ]
        }
      ]
    }
  ]
}